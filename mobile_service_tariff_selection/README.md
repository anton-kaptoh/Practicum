# Модель подбора тарифа для клиента мобильного оператора

Разработана модель, подбирающая клиенту оптимальный для перехода тариф мобильной связи. Проведено исследование зависимости различных моделей от их гиперапарметров.

## Ссылка на полноценный просмотр ноутбука

https://nbviewer.org/github/anton-kaptoh/Practicum/blob/main/mobile_service_tariff_selection/MobileServiceTariffClassification.ipynb

## Tags
hyperparameters analysis, LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, scikit-learn, matplotlib, seaborn

## Шаги/ход исследования
- [1. Рекомендация тарифов](#1.-Рекомендация-тарифов)
  - [1.1. Загрузка данных](#1.1.-Загрузка-данных)
  - [1.2. Разбиение данных на выборки](#1.2.-Разбиение-данных-на-выборки)
  - [1.3. Обучение моделей](#1.3.-Обучение-моделей)
    - [1.3.1. Модель LogisticRegression](#1.3.1.-Модель-LogisticRegression)
    - [1.3.2. Модели DecisionTreeClassifier и RandomForestClassifier](#1.3.2.-Модели-DecisionTreeClassifier-и-RandomForestClassifier)
      - [1.3.2.1. Модель DecisionTreeClassifier - результаты](#1.3.2.1.-Модель-DecisionTreeClassifier---результаты)
      - [1.3.2.2. Модель RandomForestClassifier - гиперпараметр числа деревьев](#1.3.2.2.-Модель-RandomForestClassifier---гиперпараметр-числа-деревьев)
    - [1.3.3. Сводные данные по моделям](#1.3.3.-Сводные-данные-по-моделям)
  - [1.4. Тестирование модели](#1.4.-Тестирование-модели)
  - [1.5. Проверка модели на адекватность](#1.5.-Проверка-модели-на-адекватность)
  - [1.6. Общий вывод](#1.6.-Общий-вывод)

## Выводы
Исследовав модели классификации LogisticRegression, DecisionTreeClassifier и RandomForestClassifier на данных по мобильным тарифам мы обнаружили следующее:

* В датасете была обнаружена практически линейная связь между calls и minutes и для предотвращения <b>мультиколлинеарности</b> call и minutes в факторах(features) из двух оставили только столбец minutes.

* Для модели <b>LogisticRegression</b> максимальное значение accuracy по валидационной выборке `0.754277`, `0.755832` получается для алгоритмов newton-cg и lbfgs соответственно. Причем lbfgs обучается быстрее чем newton-cg примерно в 4 раза (seconds_fit_runs), а для достижения максимальной точности lbfgs требуется на 4-13 итераций (значение max_iter) больше чем для newton-cg. Кроме того, на графике видно, что если у алгоритма newton-cg значение accuracy практически постоянно растет с увеличением параметра max_iter до уровня "насыщения" , то у lbfgs наблюдатся сильные колебания в показаниях качества модели в диапазоне max_iter ~ [20-50] и потом она приходит к тому же уровню, что и newton-cg. Остальные алгоритмы получают на валидационной выборке более плохой результат для accuracy, ниже целевого 0.75.

* Для модели <b>DecisionTreeClassifier</b> максимальное значение accuracy по валидационной выборке `0.783826` получается для глубины дерева (`max_depth`), равной `3` и `4`.

* Максимальное значение accuracy модели <b>RandomForestClassifier</b> для валидационного датасета `0.804044` достигается при близком значении accuracy для тренировочного датасета `0.795643`, а далее модель при увеличении глубины деревьев уходит в "зону переобучения". В то же время много значений числа деревьев (n_estimators) в диапазонах [154..211] и [325..450] показали одинаково максимальный результат качества модели на валидационной выборке при глубине дерева = 3.

* Если проводить <b>сравнение моделей</b> между собой:
    * Самые высокие значения accuracy на валидационной выборке получаются у модели RandomForestClassifier. Так как она является усовершенствованием (ансамблем) модели DecisionTreeClassifier, то значения accuracy даже при неоптимальных выборах параметра числа деревьев, все равно при глубине деревьев 2 и более всегда превышают значения accuracy для DTC. 
    * На обучающей выборке различия в качестве моделей DTC и RFC уже имеют другой характер: здесь accuracy для DTC близка к максимальным значениям для RFC, а при неоптимальном выборе числа деревьев для RFC accuracy у RFC модели может получиться и ниже. 
    * LogisticRegressions на валидационной выборке показывает результаты лучше чем она же на обучающей выборке. По сравнению с остальными ее максимальные значения accuracy конкурируют с DTC и RFC моделями лишь при неоптимальных значениях их гиперпараметров (с RFC - только при max_depth = 1, c DTC - при max_depth = 1 и max_depth > 8)

* Рассмотрев результаты выбранных моделей <b>на тестовой выборке</b> можно увидеть, что их качество предсказания (accuracy) превысило результаты не только для валидационной выборки но и для обучающей. Лучше всех себя опять показала модель RandomForestClassifier, на втором месте - DecisionTreeClassifier, а на третьем месте совсем немногим превысив целевой показатель значения accuracy - LogisticRegression. В целом видно, что выбранные значения гиперпараметров достаточно оптимально работают и на тестовой выборке.

* При проверке модели на <b>адекватность</b>, что значение accuracy в случае случайного выбора is_ultra стремится к 0.5. Что говорит о том, что модель классификации действительно работает и результат ее предсказания лучше случайного выбора значения (accuracy ~0.817 на тестовой выборке).
