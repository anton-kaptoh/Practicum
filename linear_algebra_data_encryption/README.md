# Линейная алгебра, шифрование личных данных клиентов

Разработан алгоритм для шифрования данных с помощью матричных операций. Доказано аналитчески и экспериментально, что алгоритм не влияет на функцию потерь и качество обучения ML-модели сохраняется. 

## Ссылка на полноценный просмотр ноутбука

https://nbviewer.org/github/anton-kaptoh/Practicum/blob/main/linear_algebra_data_encryption/LinearAlgebraDataEncryption.ipynb

## Tags
linear algebra, matrix operations, numpy, LinearRegression, regression, pipeline, scikit-learn

## Шаги/ход исследования
- [1. Защита персональных данных клиентов](#1.-Защита-персональных-данных-клиентов)
  - [1.1. Импорты](#1.1.-Импорты)
  - [1.2. Загрузка данных](#1.2.-Загрузка-данных)
    - [1.2.1. Pandas profiling](#1.2.1.-Pandas-profiling)
  - [1.3. Умножение матриц](#1.3.-Умножение-матриц)
    - [1.3.1. Получение формулы для весов линейной регрессии](#1.3.1.-Получение-формулы-для-весов-линейной-регрессии)
    - [1.3.2. Получение формулы для весов линейной регрессии после преобразования](#1.3.2.-Получение-формулы-для-весов-линейной-регрессии-после-преобразования)
  - [1.4. Алгоритм преобразования](#1.4.-Алгоритм-преобразования)
    - [1.4.1. Класс-шифровальщик](#1.4.1.-Класс-шифровальщик)
  - [1.5. Проверка алгоритма](#1.5.-Проверка-алгоритма)
    - [1.5.1. Разделение на обучающую/тестовую выборки](#1.5.1.-Разделение-на-обучающую/тестовую-выборки)
    - [1.5.2. DummyRegressor](#1.5.2.-DummyRegressor)
    - [1.5.3. Класс линейной регрессии](#1.5.3.-Класс-линейной-регрессии)
    - [1.5.4. Результаты исходной задачи](#1.5.4.-Результаты-исходной-задачи)
    - [1.5.5. Результаты зашифрованной задачи](#1.5.5.-Результаты-зашифрованной-задачи)
    - [1.5.6. Pipeline](#1.5.6.-Pipeline)
    - [1.5.7. Pipeline для LinearRegression из sklearn](#1.5.7.-Pipeline-для-LinearRegression-из-sklearn)
  - [1.6. Выводы](#1.6.-Выводы)

## Выводы
В данной работе мы нашли способ защитить численные персональные данные путем умножения признаков на обратимую матрицу. Мы показали, что функция потерь при таком преобразовании признаков не меняется, соответственно качество модели остается тем же. Мы также подтвердили это экспериментально различными способами, измеряя метрику коэффициента детериминации R2. Кроме того, мы, ожидаемо, получили серьезное увеличение R2-метрики по сравению с dummy моделью.