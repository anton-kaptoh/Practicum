# Модель классификации токсичных комментариев

Разработана модель классификации токсичных комментариев. Производился fine-tuning
BERT-моделей и обучались различные класссические модели на эмбеддингах. 

## Ссылка на полноценный просмотр ноутбука

https://nbviewer.org/github/anton-kaptoh/Practicum/blob/main/text_toxicity_classification/ToxicityTextClassificationBERT.ipynb

## Tags
NLP, DistillBERT, RoBERTa, TensorFlow, PyTorch, transformers, CatBoost

## Шаги/ход исследования
- [1. Проект для выявления тоскичных комментариев](#1.-Проект-для-выявления-тоскичных-комментариев)
  - [1.1. Описание проекта](#1.1.-Описание-проекта)
  - [1.2. Импорты](#1.2.-Импорты)
  - [1.3. Тесты совместимости с CUDA](#1.3.-Тесты-совместимости-с-CUDA)
  - [1.4. Подготовка](#1.4.-Подготовка)
  - [1.5. Загрузка данных](#1.5.-Загрузка-данных)
    - [1.5.1. Анализ данных](#1.5.1.-Анализ-данных)
    - [1.5.2. Выделение тестовой и валидационной выборки](#1.5.2.-Выделение-тестовой-и-валидационной-выборки)
  - [1.6. Обучение](#1.6.-Обучение)
    - [1.6.1. Константная модель](#1.6.1.-Константная-модель)
    - [1.6.2. Aux functions](#1.6.2.-Aux-functions)
    - [1.6.3. DistilBert](#1.6.3.-DistilBert)
      - [1.6.3.1. Model initialization](#1.6.3.1.-Model-initialization)
      - [1.6.3.2. Validation of pre-trained](#1.6.3.2.-Validation-of-pre-trained)
        - [1.6.3.2.1. Результаты](#1.6.3.2.1.-Результаты)
        - [1.6.3.2.2. Выводы](#1.6.3.2.2.-Выводы)
      - [1.6.3.3. Sampled dataset](#1.6.3.3.-Sampled-dataset)
        - [1.6.3.3.1. Validation](#1.6.3.3.1.-Validation)
          - [1.6.3.3.1.1. Результаты](#1.6.3.3.1.1.-Результаты)
        - [1.6.3.3.2. Выводы](#1.6.3.3.2.-Выводы)
      - [1.6.3.4. Full dataset](#1.6.3.4.-Full-dataset)
        - [1.6.3.4.1. Validation](#1.6.3.4.1.-Validation)
          - [1.6.3.4.1.1. Результаты](#1.6.3.4.1.1.-Результаты)
        - [1.6.3.4.2. Выводы](#1.6.3.4.2.-Выводы)
    - [1.6.4. Roberta toxic](#1.6.4.-Roberta-toxic)
      - [1.6.4.1. Model initialization](#1.6.4.1.-Model-initialization)
      - [1.6.4.2. Validation of pre-trained](#1.6.4.2.-Validation-of-pre-trained)
        - [1.6.4.2.1. Результаты](#1.6.4.2.1.-Результаты)
        - [1.6.4.2.2. Выводы](#1.6.4.2.2.-Выводы)
      - [1.6.4.3. Full dataset](#1.6.4.3.-Full-dataset)
        - [1.6.4.3.1. Validation](#1.6.4.3.1.-Validation)
        - [1.6.4.3.2. Выводы](#1.6.4.3.2.-Выводы)
      - [1.6.4.4. Sampled dataset](#1.6.4.4.-Sampled-dataset)
        - [1.6.4.4.1. Validation](#1.6.4.4.1.-Validation)
          - [1.6.4.4.1.1. Результаты](#1.6.4.4.1.1.-Результаты)
        - [1.6.4.4.2. Выводы](#1.6.4.4.2.-Выводы)
      - [1.6.4.5. Balanced dataset](#1.6.4.5.-Balanced-dataset)
        - [1.6.4.5.1. Creating balanced dataset](#1.6.4.5.1.-Creating-balanced-dataset)
        - [1.6.4.5.2. Fine-tuning model](#1.6.4.5.2.-Fine-tuning-model)
        - [1.6.4.5.3. Validation](#1.6.4.5.3.-Validation)
          - [1.6.4.5.3.1. Результаты](#1.6.4.5.3.1.-Результаты)
        - [1.6.4.5.4. Выводы](#1.6.4.5.4.-Выводы)
    - [1.6.5. Embeddings](#1.6.5.-Embeddings)
      - [1.6.5.1. Embeddings from distillbert](#1.6.5.1.-Embeddings-from-distillbert)
      - [1.6.5.2. Embeddings from distillbert trained](#1.6.5.2.-Embeddings-from-distillbert-trained)
      - [1.6.5.3. Embeddings from Bert](#1.6.5.3.-Embeddings-from-Bert)
      - [1.6.5.4. Embeddings from Roberta](#1.6.5.4.-Embeddings-from-Roberta)
      - [1.6.5.5. Логистическая регрессия](#1.6.5.5.-Логистическая-регрессия)
        - [1.6.5.5.1. Roberta embeddings](#1.6.5.5.1.-Roberta-embeddings)
          - [1.6.5.5.1.1. Validation](#1.6.5.5.1.1.-Validation)
        - [1.6.5.5.2. Distillbert fine-tuned embeddings](#1.6.5.5.2.-Distillbert-fine-tuned-embeddings)
          - [1.6.5.5.2.1. Validation](#1.6.5.5.2.1.-Validation)
        - [1.6.5.5.3. Bert base trained embeddings](#1.6.5.5.3.-Bert-base-trained-embeddings)
          - [1.6.5.5.3.1. Validation](#1.6.5.5.3.1.-Validation)
        - [1.6.5.5.4. Выводы](#1.6.5.5.4.-Выводы)
      - [1.6.5.6. Дерево решений](#1.6.5.6.-Дерево-решений)
        - [1.6.5.6.1. Выводы](#1.6.5.6.1.-Выводы)
      - [1.6.5.7. Случайный лес](#1.6.5.7.-Случайный-лес)
        - [1.6.5.7.1. Roberta embeddings](#1.6.5.7.1.-Roberta-embeddings)
          - [1.6.5.7.1.1. Full train dataset GridSearchCV](#1.6.5.7.1.1.-Full-train-dataset-GridSearchCV)
          - [1.6.5.7.1.2. Validation](#1.6.5.7.1.2.-Validation)
        - [1.6.5.7.2. Bert base embeddings](#1.6.5.7.2.-Bert-base-embeddings)
          - [1.6.5.7.2.1. Validation](#1.6.5.7.2.1.-Validation)
        - [1.6.5.7.3. Distillbert fine-tuned embeddings](#1.6.5.7.3.-Distillbert-fine-tuned-embeddings)
          - [1.6.5.7.3.1. Validation](#1.6.5.7.3.1.-Validation)
        - [1.6.5.7.4. Выводы](#1.6.5.7.4.-Выводы)
      - [1.6.5.8. CatBoost](#1.6.5.8.-CatBoost)
        - [1.6.5.8.1. Сравнение обучения на CPU и GPU](#1.6.5.8.1.-Сравнение-обучения-на-CPU-и-GPU)
        - [1.6.5.8.2. DistilBert embeddings](#1.6.5.8.2.-DistilBert-embeddings)
          - [1.6.5.8.2.1. Full train dataset GridSearchCV](#1.6.5.8.2.1.-Full-train-dataset-GridSearchCV)
          - [1.6.5.8.2.2. Validation](#1.6.5.8.2.2.-Validation)
        - [1.6.5.8.3. Bert base embeddings](#1.6.5.8.3.-Bert-base-embeddings)
          - [1.6.5.8.3.1. Full train dataset GridSearchCV](#1.6.5.8.3.1.-Full-train-dataset-GridSearchCV)
          - [1.6.5.8.3.2. Validation](#1.6.5.8.3.2.-Validation)
        - [1.6.5.8.4. Roberta embeddings](#1.6.5.8.4.-Roberta-embeddings)
          - [1.6.5.8.4.1. Full train dataset GridSearchCV](#1.6.5.8.4.1.-Full-train-dataset-GridSearchCV)
          - [1.6.5.8.4.2. Validation](#1.6.5.8.4.2.-Validation)
          - [1.6.5.8.4.3. Validation with words count](#1.6.5.8.4.3.-Validation-with-words-count)
        - [1.6.5.8.5. Distillbert fine-tuned embeddings](#1.6.5.8.5.-Distillbert-fine-tuned-embeddings)
          - [1.6.5.8.5.1. Full train dataset GridSearchCV](#1.6.5.8.5.1.-Full-train-dataset-GridSearchCV)
          - [1.6.5.8.5.2. Validation](#1.6.5.8.5.2.-Validation)
        - [1.6.5.8.6. Выводы](#1.6.5.8.6.-Выводы)
  - [1.7. Тестирование](#1.7.-Тестирование)
    - [1.7.1. Выводы](#1.7.1.-Выводы)
  - [1.8. Выводы](#1.8.-Выводы)

## Выводы
Мы использовали различные языковые модели (BERT и его аналоги DistillBERT и RoBERTa) для задачи классификации комментариев по их токсичности путем обучения самих языковых моделей на наших данных, а также путем использования эмбеддингов, полученных от этих языковых моделей для обучения LogisticRegression, DecisionTreeClassifier, RandomForestClassifier и CatBoostClassifier.
* Лучше всех себя показала модель CatBoost поверх эмбеддингов от Roberta-toxicity-classifier с дополнительным признаком числа слов в комментарии (F1 ~0.872 при необходимых 0.75)
* Результаты предсказаний предобученной языковой модели Roberta-toxicity-classifier совсем немногим уступает CatBoost-у с доп. признаком (F1 0.8693 против 0.8722)
* Результаты всех моделей поверх эмбеддингов коррелируют с результатами предсказаний самих языковых моделей на наших данных (чем лучше предсказывает языковая модель, тем лучше резульаты на её эмбеддингах)
* Генерация эмбеддингов с помощью torch используя GPU получалась немногим быстрее чем получение самих предсказаний от модели с помощью tensorflow
  * для Roberta-toxicity-classifier CPU times для генерации выборки размером с валидационную: 12min 41s против 17min 34s
  * для обученного нами DistillBert CPU times для генерации выборки размером с валидационную: 7min 30s против 8min 40s
  *  С учетом того что CatBoost предсказания по нашим тестам происходят очень быстро (CPU times: 5.7 s для тестового датасета) можно получить некое улучшение быстродействия модели относительно предсказаний напрямую языковой моделью.