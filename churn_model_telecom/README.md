# Телеком — модель оттока

Построена модель оттока клиентов телеком-оператора. Информация о договорах актуальна на 1 февраля 2020. Лучшая модель полученная с помощью optuna - CatBoost, ROC-AUC 0.95. 

## Ссылка на полноценный просмотр ноутбука

https://nbviewer.org/github/anton-kaptoh/Practicum/blob/main/churn_model_telecom/ChurnModelTelecom.ipynb

## Tags
classification, pandas, scikit-learn, EDA, pipeline, Optuna, CatBoost, RandomForest, LogisticRegression, Matplotlib, seaborn

## Описание данных

* customerID - код клиента
* BeginDate - дата начала пользования услугами
* EndDate - дата окончания пользования услугами
* Type - период оплаты: раз месяц или раз в год/два года
* PaperlessBilling - получение электронного чека вместо бумажного
* PaymentMethod - тип платежа (электронная квитанция/квитанция на e-mail/автоматический платеж через банк)
* MonthlyCharges - ежемесячные траты на услуги
* TotalCharges - всего потрачено денег на услуги
* gender - пол абонента
* SeniorCitizen - пенсионер
* Partner - наличие супруга(и)
* Dependents - наличие иждивенцев
* InternetService - подключена ли услуга интернета
* OnlineSecurity - подключена ли услуга блокировки небезопасных сайтов
* OnlineBackup - подключена ли услуга "Облачное хранилище файлов для резервного копирования данных"
* DeviceProtection - подключена ли услуга антивируса
* TechSupport - подключена ли услуга "Выделенная линия технической поддержки"
* StreamingTV - подключена ли услуга "Стриминговое телевидение"
* StreamingMovies подключена ли услуга "Каталог фильмов"
* MultipleLines - несколько линий стационарной тел. связи

## Шаги/ход исследования
1. <b>Знакомство с задачей и данными, предварительный анализ</b>
    * <i>знакомство с ТЗ</i>
        * проанализировали его данные
        * увидели, что данные состоят из нескольких csv-файлов с ключевым полем customerID
        * увидели дату актальности данных 1 февраля 2020
    * <i>чтение данных и анализ структуры данных</i>
        * прочитали данные из 4 файлов
        * посмотрели на список полей и их типы в получившихся 4 таблицах: в основном типы object, по наполнению увидели, что можно их приводить к category / boolean/ float / datetime
    * <i>предобработка, предварительный разведочный анализ (EDA) для формулирования вопросов к заказчику</i>
        * проанализировали поле customerID и полноту данных в 4 таблицах
            * получили, что больше всего клиентов, у которых подключены услуги и телефонии и интернета , далее клиенты только с телефонией , и меньше всего клиентов с один лишь интернетом (628)
            * проанализировали их также в разбивке по целевому признаку: больше всего клиентов ушло будучи подключенными к обеим услугам (1586 против 3249 оставшихся), клиентов подключенных только к интернету ушло 170 к 512 оставшимся, а из клиентов подключенных только к телефонии ушло меньше всего - 113 к 1413
        * объединили данные в один датафрейм по полю customerID, привели названия к snake_case
        * привели типы данных к корректным:
            * begin_date, end_date - datetime
            * gender, paperless_billing, partner, dependents, online_security, online_backup, device_protection, tech_support, streaming_tv, streaming_movies, senior_citizen, multiple_lines - boolean
            * type, payment_method, internet_service - category
            * выделили отдельные признаки has_phone, has_internet
            * выделили целевой признак exited на основе признака end_date (если не пустой)
        * добавили синтетические признаки для анализа: 
            * продолжительность договора с клиентом в месяцах
            * численный признак долга/переплаты
            * месяц начала договора клиента - только для анализа
        * провели предварительное EDA с помощью библиотек sweetviz и ydata-profiling 
            * сделали выводы по взимосвязям между столбцами и целевым признаком, обнаружили достаточно высокие корреляции, увидели нисходящий тренд у monthly_charges
    * <i>обсуждение с заказчиком (или другим уполномоченным лицом) - обсудили с тимлидом</i>        
        * примерный вид результата
        * требования и этапы работы
            * метрика качества - ROC-AUC
            * тестовые данные - 25%
            * получили полное описание полей, RANDOM_STATE=130323
            * минимум 2 модели обучить (бустинг + классическая)
            * этапы:
                * Первичное знакомство / загрузка данных
                * Исследовательский анализ данных
                * Моделирование
                * Тестирование и выводы        
        * вопросов появившихся после EDA (например, вопросов по признакам, полноте данных, источнике данных и т.д.)
            * обсудили данные, end_date - только 4 месяца уникальных
            
 
           
2. <b>Исследовательский анализ данных и обработка</b>
    * <i>доработка EDA после уточнения целей</i>
        * добавили отдельную heatmap-матрицу корреляций Phik (работает для всех типов признаков)
        * добавили pairplot (для анализа взаимосвязей между числовыми столбцамии), где увидели практически четкую границу по целевому признаку для синтетического признака долга/переплаты
    * <i>feature extraction & engineering - извлечение из данных новых признаков и преобразование признаков в понятный для модели вид</i>
        * для дальнейшего использовния в pipeline из синтетических выбрали  признаки длительности контракта клиента и долга/переплаты,
    * <i>анализ и обработка пропусков, выбросов, аномалий</i>
        * обработали пропуски:
                * заполнили total_charges на основе monthly_charges и длительности контракта клиента в месяцах
                * заполнили в internet_service пропуски на "n/a" - для того, чтобы не использовать отдельный признак has_internet (Catboost обработает internet_service как категорию, для лог. регрессии - обработаем OneHotEncoder-ом)
        * Посмотрели на диаграммы размаха численных признаков, увидели выбросы на нашем синтетическом признаке долга/переплаты, которые и являлись показателями ухода, поэтому выбросы не обрабатывали
        * нашли аномалии в данных
            * для самых ранних 3 месяцев в begin_date - ушли все клиенты, но решили эти данные не удалять
    * <i>feature selection - отбор признаков для использования в модели</i>
        * провели дополнительный анализ утечки целевого признака, где заключили что наш синтетический признак долга/переплаты не является утечкой
        * для дальнейшего использовния в pipeline из синтетических выбрали  признаки длительности контракта клиента и численный признак долга/переплаты,
        * проанализировали корреляции: добавили в перебор параметров для лог. регрессии исключение monthly_charges
     
   
        
3. <b>Обучение моделей</b>
    * <i>разбиение данных (CV, 25% - тестовые, random_state=130323)</i>
        * разбили данные на тестовые (25%) и обучающие, train_test_split с random_state=130323 и stratify по целевому признаку
    * <i>построение dummy-модели как baseline для сравнения</i>
        * использовали DummyClassifier со стратегией "stratified", ожидаемо показал неудовлетворительное значение roc_auc ~ 0.5
    * <i>выбор моделей для обучения и построение для них пайплайнов (возможно, с использованием кодирования/масштабирования или других типов преобразований в зависимости от модели)</i>
        * выбрали CatBoostClassifier, LogisticRegression, RandomForestClassifier для сравнениях их качества на кросс-валидации
        * построили пайплайны
            * для feature extraction
                * извлекли признаки длительности контракта клиента и численный признак долга/переплаты
            * для обработки категориальных признаков
                * замена пропусков
                * для RandomForestClassifier - OrdinalEncoder
            * для обработки численных признаков
                * замена пропусков
                * для LogisticRegression - StandardScaler/PowerTransformer
            * объединили пайплайны для обработки категориальных/численных признаков с помощью ColumnTransformer
            * объединили для каждой модели все пайплайны в один и добавили удаление признаков с помощью трансформера DropFeatures из feature-engine и в качестве последнего шага добавили сам estimator
    * <i>кросс-валидация, подбор гиперпараметров моделей</i>
        * подбирали параметры на кросс-валидации: CV = StratifiedKFold(shuffle=True, random_state=130323)
        * использовали optuna в sklearn-стиле с помощью класса optuna.integration.OptunaSearchCV
        * направление оптимизации - maximize, метрика - roc_auc
        * было выполнено по 10 итераций перебора гиперпараметров для каждой модели
    *  <i>сравнение качества моделей</i>
        * лучше всех среди рассмотренных нами моделей c небольшим отрывом показал себя градиентный бустинг CatBoost (ROC-AUC 0.939 на CV), 
        * на втором месте - лог.регрессия (ROC-AUC 0.938 на CV), 
        * на третьем - RandomForestClassifier (0.936)
4. <b>Тестирование модели, оформление результатов</b>
    * тестирование лучшей модели
        * CatBoost показал результат на тестовых данных для ROC-AUC 0.947
    * анализ результатов тестирования, выводы
        * анализ, выводы ниже
    * подготовили результаты:
        * определили важности признаков - вывели feature importance для нашей лучшей модели 
        * построили ROC кривые для предсказаний по фолдам при кросс-валидации и по предсказаниям для тестовых данных при обучении на полных train-данных
        * построили также для всех фолдов и тестовых данных матрицы ошибок
        
## Выводы



* Итоговая модель - `CatBoostClassifier`

* <i>Для обучения модели использовались следующие признаки:</i>
    * `type`
    * `payment_method`
    * `internet_service`
    * `multiple_lines`
    * `monthly_charges`
    * `total_charges`
    * `charges_diff`
    * `charges_ratio`
    * `contract_duration_months`
    * `paperless_billing`
    * `senior_citizen`
    * `partner`
    * `dependents`
    * `online_security`
    * `online_backup`
    * `device_protection`
    * `tech_support`
    * `streaming_tv`
    * `streaming_movies`
    * `is_male`
    
* <i>В качестве предобработки признаков выполнялась</i>:

    * замена пропусков в numeric (total_charges, charges_diff, charges_ratio) на 0
    * замена пропусков в categorical/object (internet_service, multiple_lines) на "n/a"

* <i>Гиперпараметры модели</i>, полученные поиском оптимальных параметров optuna на кросс-валидации:
optuna_search.best_estimator_.named_steps.estimator.get_params()
* <i>Простраство гиперпараметров на котором производился поиск:</i>
optuna_search.param_distributions
* как видим, кроме параметров самого CatBoost-а (`max_depth`, `iterations`, `learning_rate`) смотрели на необходимость признака `monthly_charges`, `cat_features` здесь константный
* <i>Качество модели:</i>
    * <b>ROC_AUC: 0.95</b>
    * F1: 0.8
* При кросс-валидации на всех фолдах получены схожие результаты качества предсказаний (ROC-AUC: 0.93-0.95, F1: 0.73-0.82)
    * Выделяется ROC-кривая на 1 фолде (голубая кривая), самый высокий ROC-AUC благодаря высокой точности предсказаний(precision, меньше всего False Positive) 
    * сильно проседает 3-ий фолд из-за самых низких результатов и по полноте и по точности
* На тестовых данных <i>ROC-кривая</i> в отдельных местах чуть уступает кривой на лучшем фолде, что говорит нам о том, что мы достаточно удачно подобрали гиперпараметры модели, и возможно еще из-за того, что было больше данных для обучения модели(чем при кросс-валидации, хотя и тестовых данных тут больше)
* Таким образом, на тестовой выборке CatBoost показал результаты лучше, чем средние по кросс-валидации
* <i>В feature importances:</i>
    * на первом месте ожидаемо charges_diff, его аналог charges_ratio на два места ниже
    * Лучше всего в feature importances себя показали численные и категориальные признаки: все 9 в ТОП-9
    * интересно, что is_male имеет значение важности для CatBoost-а больше чем у многих гораздо более коррелирующих с целевым признаков
* Больше всего у модели ошибок типа False Negative, то есть клиент ушел, а мы предсказали, что он останется. Здесь нужно понимать, какой баланс нужен заказчику между False Negative и False Positive, насколько убыток от предполагаемых мер премирования пользователей (которые по предскаанию модели могут уйти) выгоднее чем возможная потеря клиента.
* Таким образом задача была решена с достаточно высоким значением качества, дальнейшая донастройка и внедрение модели возможно после общения с заказчиком.