# Нейросеть для определения возраста по фотографии

Построена модель для определения возраста по фото лица. Используется датасет <em><a href="http://chalearnlap.cvc.uab.es/dataset/26/description/" target="_blank">ChaLearn Looking at People</a></em>. Сравнивался MAE моделей с различными конфигурациями top-уровней, на разном железе. Результат: ResNet50 модель с MAE ~5.18 - лучше чем у авторов статьи по данному датасету. 

## Ссылка на полноценный просмотр ноутбука

https://nbviewer.org/github/anton-kaptoh/Practicum/blob/main/age_by_face_recognition/AgeFaceRecognition.ipynb

## Tags
CV, regression, Keras, image processing 


## Шаги/ход исследования

- [1. Определение возраста по фотографии](#1.-Определение-возраста-по-фотографии)
  - [1.1. Импорты](#1.1.-Импорты)
  - [1.2. Подготовка аналогичных данных в локальной среде](#1.2.-Подготовка-аналогичных-данных-в-локальной-среде)
  - [1.3. Путь к данным в локальной среде](#1.3.-Путь-к-данным-в-локальной-среде)
  - [1.4. Загрузка данных](#1.4.-Загрузка-данных)
  - [1.5. Flow from dataframe 256](#1.5.-Flow-from-dataframe-256)
  - [1.6. Исследовательский анализ данных](#1.6.-Исследовательский-анализ-данных)
    - [1.6.1. Возраст](#1.6.1.-Возраст)
    - [1.6.2. Размеры фотографий](#1.6.2.-Размеры-фотографий)
    - [1.6.3. Выводы](#1.6.3.-Выводы)
  - [1.7. Обучение](#1.7.-Обучение)
    - [1.7.1. Обучение модели на сервере с GPU (Tesla V100-SXM2-32GB)](#1.7.1.-Обучение-модели-на-сервере-с-GPU-(Tesla-V100-SXM2-32GB))
    - [1.7.2. Обучение в локальной среде](#1.7.2.-Обучение-в-локальной-среде)
      - [1.7.2.1. Initial model config (batch size 16)](#1.7.2.1.-Initial-model-config-(batch-size-16))
      - [1.7.2.2. Обучение за два этапа](#1.7.2.2.-Обучение-за-два-этапа)
      - [1.7.2.3. Batch size 32](#1.7.2.3.-Batch-size-32)
      - [1.7.2.4. Image size 300x300, learning rate 0.00005, first Dense layer size 256](#1.7.2.4.-Image-size-300x300,-learning-rate-0.00005,-first-Dense-layer-size-256)
        - [1.7.2.4.1. Сохранение модели](#1.7.2.4.1.-Сохранение-модели)
        - [1.7.2.4.2. Дополнительно обучение модели](#1.7.2.4.2.-Дополнительно-обучение-модели)
      - [1.7.2.5. Added horizontal flip](#1.7.2.5.-Added-horizontal-flip)
        - [1.7.2.5.1. Сохранение модели](#1.7.2.5.1.-Сохранение-модели)
      - [1.7.2.6. Added horizontal flip and reduced image size](#1.7.2.6.-Added-horizontal-flip-and-reduced-image-size)
  - [1.8. Тестирование](#1.8.-Тестирование)
  - [1.9. Выводы](#1.9.-Выводы)

## Выводы
Мы провели множество экспериментов в двух средах с различными конфигурациями нашей нейросети, входных данных, оптимизационных алгоритмов и других настроек обучения. Было получено итоговое MAE ~ 5.1836, немногим лучше результата в <a href='http://people.ee.ethz.ch/~timofter/publications/Agustsson-FG-2017.pdf'>статье</a> об используемом датасете.

* При обучении в локальной среде с GPU RTX 2070 при целевом размере изображения 256x256 и размере батча 16 на 50 эпохах мы получили уже удовлетворяющее нас значение MAE на валидации (<8). 
* Увеличение размера батча в локальной среде до максимума помещающегося в видеопамять (32) позволило нам немного снизить значениее MAE на валидации, а дальнейшее увеличение разрешения изображения до 300x300, уменьшение в 2 раза learning rate Adam, и снижение числа нейронов в первом полносвязном поверх ResNet слое позволило значительно снизить значение MAE на валидации и получить итоговый результат MAE ~ 5.3492.
* Дальнейшее дообучение даже при дальнейшем уменьшении learning rate Adam-а этой лучшей модели не привело к улучшению показателей ее качества на валидационной выборке.
* При обучении на сервере с GPU, имеющем большой объем видеопамяти и позволяющий выбрать размер батча равным 64, нам удалось получить значение лишь только ~6 для MAE с теми же настройками что были выбраны при обучении топовой нейросети в локальной среде.
* Добавление аугментации типа горизонтального отражения в ImageDataGenerator позволило еще немного снизить значение качества MAE - до <b>5.1836</b> в локальной среде и до 5.6379 на сервере с GPU